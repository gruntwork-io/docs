---
hide_table_of_contents: true
hide_title: true
custom_edit_url: null
---

import CenterLayout from "/src/components/CenterLayout"
import GitHub from "/src/components/GitHub"

<CenterLayout>
<span className="searchCategory">Knowledge Base</span>
<h1>How do I bootstrap Gruntwork Pipelines and the ECS Deploy Runner?</h1>
<GitHub discussion={{"id":"D_kwDOF8slf84APRUR","number":349,"author":{"login":"yorinasub17"},"title":"How do I bootstrap Gruntwork Pipelines and the ECS Deploy Runner?","body":"I am looking to update from an older Reference Architecture that did not include the ECS Deploy Runner to a modern version, and am stuck trying to figure out how to deploy the ECS Deploy Runner. What are the steps needed to get the deploy runner provisioned and setup?","bodyHTML":"<p dir=\"auto\">I am looking to update from an older Reference Architecture that did not include the ECS Deploy Runner to a modern version, and am stuck trying to figure out how to deploy the ECS Deploy Runner. What are the steps needed to get the deploy runner provisioned and setup?</p>","answer":{"body":"We have [a guide for this exact thing](https://docs.gruntwork.io/guides/build-it-yourself/pipelines/deployment-walkthrough/deploy-the-ecs-deploy-runner), but to be completely transparent, (as of this comment) this guide is admittedly outdated. We are working on initiatives to massively overhaul those docs, but unfortunately don’t have anything that would be ready in the meantime so there will be a bit of a struggle for getting the ECS deploy runner up and running from scratch.\r\n\r\nWith that said, I can definitely help out with a rudimentary guide for setting up the pipeline:\r\n\r\n### Setup Machine User access\r\n\r\n1. Setup a machine user for access to the repo and create Personal Access Tokens that the ECS Deploy Runner can use to access the repos. You can follow the steps in [this guide](https://docs.gruntwork.io/guides/reference-architecture/configuration-guide/#set-up-the-machine-user), but ignore the steps around putting the ARNs in the form. We will instead be putting these ARNs directly in `terragrunt.hcl`.\r\n\r\n2. Provision an SSH key for authenticating as the machine user, and upload it the private key to Secrets Manager. You can follow the steps in [the guide](https://docs.gruntwork.io/guides/build-it-yourself/pipelines/deployment-walkthrough/deploy-the-ecs-deploy-runner#create-secrets-manager-entries) to create it. Note that you will want to create this in the shared account.\r\n\r\n3. Once those secrets manager entries are setup in the shared account, you will want to setup cross account access, which can be done with:\r\n\r\n    1. Create a KMS key that is accessible in each account (necessary for allowing decryption of secrets manager across accounts). This is done in `account-baseline`, with the terraform code: https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/shared/_global/account-baseline/terragrunt.hcl#L48-L61. If you don’t have `account-baseline` deployed, you can use the exact same map as an input to https://github.com/gruntwork-io/terraform-aws-security/tree/master/modules/kms-master-key-multi-region\r\n\r\n    1. Once the shared secret KMS key is created, update the secrets manager entries created above to rekey using the new KMS key. This is best done manually in the AWS web console.\r\n\r\n    1. Deploy https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/shared/us-west-2/_regional/shared-secret-resource-policies/terragrunt.hcl to allow cross account access to the two secrets manager entries created above. **Make sure to update the ARNs to reference the ones you created above!** Note that you can omit `GitHubPAT` if you are using GitHub as your VCS system.\r\n\r\n### Build Deploy Runner container images\r\n\r\nEach of the accounts should have access to the PAT and private SSH key for the machine user in the shared account now. The next step is to setup the container images used by the deploy runner:\r\n\r\n1. In the shared account, create the ECR repos to host the deploy-runner and kaniko images. You can use the `ecr-repos` terragrunt config in the [for-production service catalog example](https://github.com/gruntwork-io/terraform-aws-service-catalog/tree/master/examples/for-production/infrastructure-live/shared/us-west-2/_regional/ecr-repos) to create the repos.\r\n\r\n2. Once you have the ECR repos, follow the steps in [this knowledge base article](https://github.com/gruntwork-io/knowledge-base/discussions/45) to build and upload the docker images to ECR.\r\n\r\n### Deploy ECS Deploy Runner\r\n\r\nAt this point, you should have all the necessary pieces to deploy the ECS Deploy Runner. To deploy the deploy runner, we will be using the [ecs-deploy-runner service module](https://docs.gruntwork.io/reference/services/ci-cd-pipeline/ecs-deploy-runner). The steps are:\r\n\r\n1. Create a mgmt VPC to house the deploy runner if you don't have one already. Refer to [this terragrunt.hcl config](https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/shared/us-west-2/mgmt/networking/vpc/terragrunt.hcl) and [this envcommon hcl config](https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/_envcommon/mgmt/vpc-mgmt.hcl) for an example.\r\n\r\n2. Define the same common variables as those [defined here in the example](https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/v0.85.4/examples/for-production/infrastructure-live/common.hcl#L19-L35).\r\n\r\n3. Define all the necessary read-only (for `terraform-planner`) and read-write (for `terraform-deployer`) permissions to deploy your modules in YAML files in the envcommon folder. You can use the [deploy_permissions.yml](https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/_envcommon/mgmt/deploy_permissions.yml) and [read_only_permissions.yml](https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/_envcommon/mgmt/read_only_permissions.yml) examples as a starting point.\r\n\r\n4. Define the terragrunt configurations to deploy the deploy runner. Refer to [this terragrunt.hcl config](https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/shared/us-west-2/mgmt/ecs-deploy-runner/terragrunt.hcl) and [this envcommon hcl config](https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/_envcommon/mgmt/ecs-deploy-runner.hcl) for an example. Note that the `ami-builder` and `docker-image-builder` should only be configured in the **shared** account. Also be sure to update the `git_ssh_private_key_secrets_manager_arn` and `github_pat_secrets_manager_arn` locals to refer to the actual Secrets Manager entries you created above.\r\n    - NOTE: Be sure to comment out the [ec2_worker_pool_configuration](https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/_envcommon/mgmt/ecs-deploy-runner.hcl#L194-L211) variable definition. If you later find out that you do need the EC2 based workers, you can build the AMI using the Fargate ECS Deploy Runner using the [build script](https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/shared/us-west-2/_regional/amis/build_ecs_deploy_runner_worker.sh) and add back in the configuration to deploy ECS Deploy Runner in EC2 mode.\r\n\r\n6. Finally, deploy with `terragrunt apply`.\r\n\r\nYou will need to repeat this step for each of the accounts in your environment.\r\n\r\n### Setup CI/CD pipeline scripts\r\n\r\nECS Deploy Runner acts as the main runner for infrastructure calls in your AWS account, but the core infrastructure CI/CD pipeline logic is driven by the CI server (e.g., CircleCI or GitHub actions). Thus, you will not have a full CI/CD pipeline until you provision the pipeline scripts for your `infrastructure-live` repo.\r\n\r\nTo bootstrap the pipeline, start with the version defined in the `for-production` example, and adapt it to your needs. You will need the following at a minimum:\r\n\r\n1. Copy the [_ci folder](https://github.com/gruntwork-io/terraform-aws-service-catalog/tree/master/examples/for-production/infrastructure-live/_ci), which contains all the relevant scripts to drive core parts of the pipeline, like AWS authentication and calling ECS Deploy Runner.\r\n\r\n2. Copy/Generate the pipeline config. You can refer to [.circleci/config.yml](https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/.circleci/config.yml) for CircleCI, and [.github folder](https://github.com/gruntwork-io/terraform-aws-service-catalog/tree/master/examples/for-production/infrastructure-live/.github) for GitHub Actions.\r\n\r\n3. Follow the steps in [these docs](https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/docs/04-configure-gw-pipelines.md) to configure the relevant CI platforms with the secrets for invoking the pipeline.","bodyHTML":"<p dir=\"auto\">We have <a href=\"https://docs.gruntwork.io/guides/build-it-yourself/pipelines/deployment-walkthrough/deploy-the-ecs-deploy-runner\" rel=\"nofollow\">a guide for this exact thing</a>, but to be completely transparent, (as of this comment) this guide is admittedly outdated. We are working on initiatives to massively overhaul those docs, but unfortunately don’t have anything that would be ready in the meantime so there will be a bit of a struggle for getting the ECS deploy runner up and running from scratch.</p>\n<p dir=\"auto\">With that said, I can definitely help out with a rudimentary guide for setting up the pipeline:</p>\n<h3 dir=\"auto\">Setup Machine User access</h3>\n<ol dir=\"auto\">\n<li>\n<p dir=\"auto\">Setup a machine user for access to the repo and create Personal Access Tokens that the ECS Deploy Runner can use to access the repos. You can follow the steps in <a href=\"https://docs.gruntwork.io/guides/reference-architecture/configuration-guide/#set-up-the-machine-user\" rel=\"nofollow\">this guide</a>, but ignore the steps around putting the ARNs in the form. We will instead be putting these ARNs directly in <code class=\"notranslate\">terragrunt.hcl</code>.</p>\n</li>\n<li>\n<p dir=\"auto\">Provision an SSH key for authenticating as the machine user, and upload it the private key to Secrets Manager. You can follow the steps in <a href=\"https://docs.gruntwork.io/guides/build-it-yourself/pipelines/deployment-walkthrough/deploy-the-ecs-deploy-runner#create-secrets-manager-entries\" rel=\"nofollow\">the guide</a> to create it. Note that you will want to create this in the shared account.</p>\n</li>\n<li>\n<p dir=\"auto\">Once those secrets manager entries are setup in the shared account, you will want to setup cross account access, which can be done with:</p>\n<ol dir=\"auto\">\n<li>\n<p dir=\"auto\">Create a KMS key that is accessible in each account (necessary for allowing decryption of secrets manager across accounts). This is done in <code class=\"notranslate\">account-baseline</code>, with the terraform code: <a href=\"https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/shared/_global/account-baseline/terragrunt.hcl#L48-L61\">https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/shared/_global/account-baseline/terragrunt.hcl#L48-L61</a>. If you don’t have <code class=\"notranslate\">account-baseline</code> deployed, you can use the exact same map as an input to <a href=\"https://github.com/gruntwork-io/terraform-aws-security/tree/master/modules/kms-master-key-multi-region\">https://github.com/gruntwork-io/terraform-aws-security/tree/master/modules/kms-master-key-multi-region</a></p>\n</li>\n<li>\n<p dir=\"auto\">Once the shared secret KMS key is created, update the secrets manager entries created above to rekey using the new KMS key. This is best done manually in the AWS web console.</p>\n</li>\n<li>\n<p dir=\"auto\">Deploy <a href=\"https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/shared/us-west-2/_regional/shared-secret-resource-policies/terragrunt.hcl\">https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/shared/us-west-2/_regional/shared-secret-resource-policies/terragrunt.hcl</a> to allow cross account access to the two secrets manager entries created above. <strong>Make sure to update the ARNs to reference the ones you created above!</strong> Note that you can omit <code class=\"notranslate\">GitHubPAT</code> if you are using GitHub as your VCS system.</p>\n</li>\n</ol>\n</li>\n</ol>\n<h3 dir=\"auto\">Build Deploy Runner container images</h3>\n<p dir=\"auto\">Each of the accounts should have access to the PAT and private SSH key for the machine user in the shared account now. The next step is to setup the container images used by the deploy runner:</p>\n<ol dir=\"auto\">\n<li>\n<p dir=\"auto\">In the shared account, create the ECR repos to host the deploy-runner and kaniko images. You can use the <code class=\"notranslate\">ecr-repos</code> terragrunt config in the <a href=\"https://github.com/gruntwork-io/terraform-aws-service-catalog/tree/master/examples/for-production/infrastructure-live/shared/us-west-2/_regional/ecr-repos\">for-production service catalog example</a> to create the repos.</p>\n</li>\n<li>\n<p dir=\"auto\">Once you have the ECR repos, follow the steps in <a href=\"https://github.com/gruntwork-io/knowledge-base/discussions/45\" data-hovercard-type=\"discussion\" data-hovercard-url=\"/gruntwork-io/knowledge-base/discussions/45/hovercard\">this knowledge base article</a> to build and upload the docker images to ECR.</p>\n</li>\n</ol>\n<h3 dir=\"auto\">Deploy ECS Deploy Runner</h3>\n<p dir=\"auto\">At this point, you should have all the necessary pieces to deploy the ECS Deploy Runner. To deploy the deploy runner, we will be using the <a href=\"https://docs.gruntwork.io/reference/services/ci-cd-pipeline/ecs-deploy-runner\" rel=\"nofollow\">ecs-deploy-runner service module</a>. The steps are:</p>\n<ol dir=\"auto\">\n<li>\n<p dir=\"auto\">Create a mgmt VPC to house the deploy runner if you don't have one already. Refer to <a href=\"https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/shared/us-west-2/mgmt/networking/vpc/terragrunt.hcl\">this terragrunt.hcl config</a> and <a href=\"https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/_envcommon/mgmt/vpc-mgmt.hcl\">this envcommon hcl config</a> for an example.</p>\n</li>\n<li>\n<p dir=\"auto\">Define the same common variables as those <a href=\"https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/v0.85.4/examples/for-production/infrastructure-live/common.hcl#L19-L35\">defined here in the example</a>.</p>\n</li>\n<li>\n<p dir=\"auto\">Define all the necessary read-only (for <code class=\"notranslate\">terraform-planner</code>) and read-write (for <code class=\"notranslate\">terraform-deployer</code>) permissions to deploy your modules in YAML files in the envcommon folder. You can use the <a href=\"https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/_envcommon/mgmt/deploy_permissions.yml\">deploy_permissions.yml</a> and <a href=\"https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/_envcommon/mgmt/read_only_permissions.yml\">read_only_permissions.yml</a> examples as a starting point.</p>\n</li>\n<li>\n<p dir=\"auto\">Define the terragrunt configurations to deploy the deploy runner. Refer to <a href=\"https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/shared/us-west-2/mgmt/ecs-deploy-runner/terragrunt.hcl\">this terragrunt.hcl config</a> and <a href=\"https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/_envcommon/mgmt/ecs-deploy-runner.hcl\">this envcommon hcl config</a> for an example. Note that the <code class=\"notranslate\">ami-builder</code> and <code class=\"notranslate\">docker-image-builder</code> should only be configured in the <strong>shared</strong> account. Also be sure to update the <code class=\"notranslate\">git_ssh_private_key_secrets_manager_arn</code> and <code class=\"notranslate\">github_pat_secrets_manager_arn</code> locals to refer to the actual Secrets Manager entries you created above.</p>\n<ul dir=\"auto\">\n<li>NOTE: Be sure to comment out the <a href=\"https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/_envcommon/mgmt/ecs-deploy-runner.hcl#L194-L211\">ec2_worker_pool_configuration</a> variable definition. If you later find out that you do need the EC2 based workers, you can build the AMI using the Fargate ECS Deploy Runner using the <a href=\"https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/shared/us-west-2/_regional/amis/build_ecs_deploy_runner_worker.sh\">build script</a> and add back in the configuration to deploy ECS Deploy Runner in EC2 mode.</li>\n</ul>\n</li>\n<li>\n<p dir=\"auto\">Finally, deploy with <code class=\"notranslate\">terragrunt apply</code>.</p>\n</li>\n</ol>\n<p dir=\"auto\">You will need to repeat this step for each of the accounts in your environment.</p>\n<h3 dir=\"auto\">Setup CI/CD pipeline scripts</h3>\n<p dir=\"auto\">ECS Deploy Runner acts as the main runner for infrastructure calls in your AWS account, but the core infrastructure CI/CD pipeline logic is driven by the CI server (e.g., CircleCI or GitHub actions). Thus, you will not have a full CI/CD pipeline until you provision the pipeline scripts for your <code class=\"notranslate\">infrastructure-live</code> repo.</p>\n<p dir=\"auto\">To bootstrap the pipeline, start with the version defined in the <code class=\"notranslate\">for-production</code> example, and adapt it to your needs. You will need the following at a minimum:</p>\n<ol dir=\"auto\">\n<li>\n<p dir=\"auto\">Copy the <a href=\"https://github.com/gruntwork-io/terraform-aws-service-catalog/tree/master/examples/for-production/infrastructure-live/_ci\">_ci folder</a>, which contains all the relevant scripts to drive core parts of the pipeline, like AWS authentication and calling ECS Deploy Runner.</p>\n</li>\n<li>\n<p dir=\"auto\">Copy/Generate the pipeline config. You can refer to <a href=\"https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/.circleci/config.yml\">.circleci/config.yml</a> for CircleCI, and <a href=\"https://github.com/gruntwork-io/terraform-aws-service-catalog/tree/master/examples/for-production/infrastructure-live/.github\">.github folder</a> for GitHub Actions.</p>\n</li>\n<li>\n<p dir=\"auto\">Follow the steps in <a href=\"https://github.com/gruntwork-io/terraform-aws-service-catalog/blob/master/examples/for-production/infrastructure-live/docs/04-configure-gw-pipelines.md\">these docs</a> to configure the relevant CI platforms with the secrets for invoking the pipeline.</p>\n</li>\n</ol>"}}} />

</CenterLayout>
  

<!-- ##DOCS-SOURCER-START
{
  "sourcePlugin": "github-discussions",
  "hash": "5b68fd66418297feeef38cc5d2c1dbf0"
}
##DOCS-SOURCER-END -->
