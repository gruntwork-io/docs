---
hide_table_of_contents: true
hide_title: true
custom_edit_url: null
---

import CenterLayout from "/src/components/CenterLayout"
import GitHub from "/src/components/GitHub"

<CenterLayout>
<span className="searchCategory">Knowledge Base</span>
<h1>How do you do dynamic scaling based on CPU on EKS?</h1>
<GitHub discussion={{"id":"D_kwDOF8slf84APgRa","number":411,"author":{"login":"yorinasub17"},"title":"How do you do dynamic scaling based on CPU on EKS?","body":"\nThe EKS cluster autoscaler does scaling based on Pods, but I would like to scale the cluster based on CPU. Right now, I am using the ASG modules directly to manage my worker nodes and implemented dynamic scaling at the ASG level, but it is contending with the cluster autoscaler. Any ideas on how to make the two work together?\n\n---\n\n<ins datetime=\"2022-05-10T14:10:23Z\">\n  <p><a href=\"https://support.gruntwork.io/hc/requests/108575\">Tracked in ticket #108575</a></p>\n</ins>\n","bodyHTML":"<p dir=\"auto\">The EKS cluster autoscaler does scaling based on Pods, but I would like to scale the cluster based on CPU. Right now, I am using the ASG modules directly to manage my worker nodes and implemented dynamic scaling at the ASG level, but it is contending with the cluster autoscaler. Any ideas on how to make the two work together?</p>\n<hr>\n<ins datetime=\"2022-05-10T14:10:23Z\">\n  <p dir=\"auto\"><a href=\"https://support.gruntwork.io/hc/requests/108575\" rel=\"nofollow\">Tracked in ticket #108575</a></p>\n</ins>","answer":{"body":"In general, it is a bad idea to have two different autoscaling policies for the ASGs, especially if you have multiple systems managing the scaling properties. These autoscaling systems are not designed to work with other autoscalers, and thus you will observe thrashing as the two systems fight to apply their view of the world.\r\n\r\nFor example, the cluster autoscaler only cares about Pod capacity when scaling, so it doesn't care about the CPU load and thus will decide the \"right\" size of the ASG based on the Pods. The CPU autoscaler on the other hand has no visibility in the Pod capacity, so will decide the \"right\" size based on the CPUs. If these numbers don't align, then the two systems will have different desired sizes, and will continuously try to modify the state of the world to match what they want, leading to thrashing.\r\n\r\n---\r\n\r\nThe typical way dynamic scaling by CPU is handled in the Kubernetes world is to apply the CPU based autoscaling at the Pod level, and then have the Pod autoscaling influence the cluster autoscaler. That is, you can implement [Horizontal Pod Autoscalers](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/) on your kubernetes services that will cause EKS to launch more Pods in response to CPU overload. This will in turn lead to resource contention that will prevent the Pods from launching, leading to the cluster autoscaler launching more nodes.\r\n\r\nAlternatively, you can disable the cluster autoscaler and focus entirely on CPU based scaling. This prevents you from auto scaling the cluster due to other resource contention (e.g., IP addresses), but if you are running out CPU before IPs, then should work well for your environment.","bodyHTML":"<p dir=\"auto\">In general, it is a bad idea to have two different autoscaling policies for the ASGs, especially if you have multiple systems managing the scaling properties. These autoscaling systems are not designed to work with other autoscalers, and thus you will observe thrashing as the two systems fight to apply their view of the world.</p>\n<p dir=\"auto\">For example, the cluster autoscaler only cares about Pod capacity when scaling, so it doesn't care about the CPU load and thus will decide the \"right\" size of the ASG based on the Pods. The CPU autoscaler on the other hand has no visibility in the Pod capacity, so will decide the \"right\" size based on the CPUs. If these numbers don't align, then the two systems will have different desired sizes, and will continuously try to modify the state of the world to match what they want, leading to thrashing.</p>\n<hr>\n<p dir=\"auto\">The typical way dynamic scaling by CPU is handled in the Kubernetes world is to apply the CPU based autoscaling at the Pod level, and then have the Pod autoscaling influence the cluster autoscaler. That is, you can implement <a href=\"https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/\" rel=\"nofollow\">Horizontal Pod Autoscalers</a> on your kubernetes services that will cause EKS to launch more Pods in response to CPU overload. This will in turn lead to resource contention that will prevent the Pods from launching, leading to the cluster autoscaler launching more nodes.</p>\n<p dir=\"auto\">Alternatively, you can disable the cluster autoscaler and focus entirely on CPU based scaling. This prevents you from auto scaling the cluster due to other resource contention (e.g., IP addresses), but if you are running out CPU before IPs, then should work well for your environment.</p>"}}} />

</CenterLayout>
  

<!-- ##DOCS-SOURCER-START
{
  "sourcePlugin": "github-discussions",
  "hash": "ed00db28c9b35f930ed35e5425087c1c"
}
##DOCS-SOURCER-END -->
