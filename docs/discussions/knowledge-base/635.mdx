---
hide_table_of_contents: true
hide_title: true
custom_edit_url: null
---

import CenterLayout from "/src/components/CenterLayout"
import GitHub from "/src/components/GitHub"

<head>
  <link rel="canonical" href="https://github.com/gruntwork-io/knowledge-base/discussions/635" />
</head>

<CenterLayout>
<span className="searchCategory">Knowledge Base</span>
<h1>Upgrade eks-core-services in CircleCI</h1>
<GitHub discussion={{"id":"D_kwDOF8slf84ASLMB","number":635,"author":{"login":"nadiia-kotelnikova"},"title":"Upgrade eks-core-services in CircleCI","body":"\nHello all,\r\n\r\ni ran into a problem during the EKS cluster upgrade: we recently deployed ECS deploy runner and have not yet experienced with it. When I upgraded the `eks-core-service` module, the CircleCI pipeline failed with these errors:\r\n\r\n```\r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â•·\r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ Error: Kubernetes cluster unreachable: the server has asked for the client to provide credentials\r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ \r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   with module.alb_ingress_controller[\"enable\"].helm_release.aws_alb_ingress_controller,\r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   on .terraform/modules/alb_ingress_controller/modules/eks-alb-ingress-controller/main.tf line 48, in resource \"helm_release\" \"aws_alb_ingress_controller\":\r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   48: resource \"helm_release\" \"aws_alb_ingress_controller\" {\r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ \r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â•µ\r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â•·\r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ Error: Kubernetes cluster unreachable: the server has asked for the client to provide credentials\r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ \r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   with module.aws_for_fluent_bit[\"enable\"].helm_release.aws_for_fluent_bit,\r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   on .terraform/modules/aws_for_fluent_bit/modules/eks-container-logs/main.tf line 48, in resource \"helm_release\" \"aws_for_fluent_bit\":\r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   48: resource \"helm_release\" \"aws_for_fluent_bit\" {\r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ \r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â•µ\r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â•·\r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ Error: Kubernetes cluster unreachable: the server has asked for the client to provide credentials\r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ \r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   with module.k8s_external_dns[\"enable\"].helm_release.k8s_external_dns,\r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   on .terraform/modules/k8s_external_dns/modules/eks-k8s-external-dns/main.tf line 54, in resource \"helm_release\" \"k8s_external_dns\":\r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   54: resource \"helm_release\" \"k8s_external_dns\" {\r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ \r\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â•µ\r\n```\r\n\r\nMy understanding is that `ecs-deploy-runner` ECS task does not perform Kubernetes authentication and does not have Kubernetes configuration. Does anybody know how to workaround this? \n\n---\n\n<ins datetime=\"2023-01-17T10:56:28Z\">\n  <p><a href=\"https://support.gruntwork.io/hc/requests/109797\">Tracked in ticket #109797</a></p>\n</ins>\n","bodyHTML":"<p dir=\"auto\">Hello all,</p>\n<p dir=\"auto\">i ran into a problem during the EKS cluster upgrade: we recently deployed ECS deploy runner and have not yet experienced with it. When I upgraded the <code class=\"notranslate\">eks-core-service</code> module, the CircleCI pipeline failed with these errors:</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"[ecs-deploy-runner][2023-01-16T16:42:43+0000] â•·\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ Error: Kubernetes cluster unreachable: the server has asked for the client to provide credentials\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ \n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   with module.alb_ingress_controller[&quot;enable&quot;].helm_release.aws_alb_ingress_controller,\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   on .terraform/modules/alb_ingress_controller/modules/eks-alb-ingress-controller/main.tf line 48, in resource &quot;helm_release&quot; &quot;aws_alb_ingress_controller&quot;:\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   48: resource &quot;helm_release&quot; &quot;aws_alb_ingress_controller&quot; {\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ \n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â•µ\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â•·\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ Error: Kubernetes cluster unreachable: the server has asked for the client to provide credentials\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ \n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   with module.aws_for_fluent_bit[&quot;enable&quot;].helm_release.aws_for_fluent_bit,\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   on .terraform/modules/aws_for_fluent_bit/modules/eks-container-logs/main.tf line 48, in resource &quot;helm_release&quot; &quot;aws_for_fluent_bit&quot;:\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   48: resource &quot;helm_release&quot; &quot;aws_for_fluent_bit&quot; {\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ \n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â•µ\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â•·\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ Error: Kubernetes cluster unreachable: the server has asked for the client to provide credentials\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ \n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   with module.k8s_external_dns[&quot;enable&quot;].helm_release.k8s_external_dns,\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   on .terraform/modules/k8s_external_dns/modules/eks-k8s-external-dns/main.tf line 54, in resource &quot;helm_release&quot; &quot;k8s_external_dns&quot;:\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   54: resource &quot;helm_release&quot; &quot;k8s_external_dns&quot; {\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ \n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â•µ\"><pre class=\"notranslate\"><code class=\"notranslate\">[ecs-deploy-runner][2023-01-16T16:42:43+0000] â•·\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ Error: Kubernetes cluster unreachable: the server has asked for the client to provide credentials\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ \n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   with module.alb_ingress_controller[\"enable\"].helm_release.aws_alb_ingress_controller,\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   on .terraform/modules/alb_ingress_controller/modules/eks-alb-ingress-controller/main.tf line 48, in resource \"helm_release\" \"aws_alb_ingress_controller\":\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   48: resource \"helm_release\" \"aws_alb_ingress_controller\" {\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ \n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â•µ\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â•·\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ Error: Kubernetes cluster unreachable: the server has asked for the client to provide credentials\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ \n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   with module.aws_for_fluent_bit[\"enable\"].helm_release.aws_for_fluent_bit,\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   on .terraform/modules/aws_for_fluent_bit/modules/eks-container-logs/main.tf line 48, in resource \"helm_release\" \"aws_for_fluent_bit\":\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   48: resource \"helm_release\" \"aws_for_fluent_bit\" {\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ \n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â•µ\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â•·\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ Error: Kubernetes cluster unreachable: the server has asked for the client to provide credentials\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ \n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   with module.k8s_external_dns[\"enable\"].helm_release.k8s_external_dns,\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   on .terraform/modules/k8s_external_dns/modules/eks-k8s-external-dns/main.tf line 54, in resource \"helm_release\" \"k8s_external_dns\":\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚   54: resource \"helm_release\" \"k8s_external_dns\" {\n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â”‚ \n[ecs-deploy-runner][2023-01-16T16:42:43+0000] â•µ\n</code></pre></div>\n<p dir=\"auto\">My understanding is that <code class=\"notranslate\">ecs-deploy-runner</code> ECS task does not perform Kubernetes authentication and does not have Kubernetes configuration. Does anybody know how to workaround this?</p>\n<hr>\n<ins datetime=\"2023-01-17T10:56:28Z\">\n  <p dir=\"auto\"><a href=\"https://support.gruntwork.io/hc/requests/109797\" rel=\"nofollow\">Tracked in ticket #109797</a></p>\n</ins>","answer":{"body":"Without knowing the full details of your configuration, I'll try my best to explain...\r\n\r\nFor the `ecs-deploy-runner` to be able to interact with the EKS cluster, the IAM Role the runner uses, must be mapped in the `aws-auth` ConfigMap. Had the cluster been created with the IAM Role `ecs-deploy-runner` is using, this would be unnecessary, as EKS implicitly grants admin RBAC for the IAM role that the cluster was created with. I'm assuming the cluster was created with a different role? \r\n\r\nTo fix the issue, the ECS Deploy Runner IAM Role has to be added to `aws-auth` ConfigMap. If you're using the  [`eks-aws-auth-merger`](https://github.com/gruntwork-io/terraform-aws-eks/tree/master/modules/eks-aws-auth-merger), you can use the [`eks-k8s-role-mapping`](https://github.com/gruntwork-io/terraform-aws-eks/tree/master/modules/eks-k8s-role-mapping) to create an entry in the `aws-auth` ConfigMap, e.g.\r\n\r\n```\r\nmodule \"ecs_deploy_runner_eks_k8s_role_mapping\" {\r\n  source = \"git::git@github.com:gruntwork-io/terraform-aws-eks.git//modules/eks-k8s-role-mapping?ref=v0.x.x\"\r\n\r\n  name      = \"ecs-deploy-runner\"\r\n  namespace = \"whatever-namespace-you-use-for-auth-merger\"\r\n\r\n  eks_worker_iam_role_arns                   = []\r\n  eks_fargate_profile_executor_iam_role_arns = []\r\n\r\n  iam_role_to_rbac_group_mappings = {\r\n    # I'm assuming you want admin level permissions in the cluster, because you'll be deploying\r\n    # RBAC resources, hence the system:masters\r\n    \"your-ecs-deploy-runner-iam-role\"    = [\"system:masters\"]\r\n  }\r\n\r\n  config_map_labels = {\r\n    eks-cluster = module.eks_cluster.eks_cluster_name\r\n  }\r\n}\r\n```\r\nMake sure you're not overwriting the entire `aws-auth` ConfigMap ðŸ˜… and check the plan results carefully before applying. Note that you'll have to deploy the module with an IAM Role that has sufficient permissions in the EKS cluster. After the `aws-auth` ConfigMap has been updated, applying with the `ecs-deploy-runner` should work.\r\n\r\nHope this helps!\r\n","bodyHTML":"<p dir=\"auto\">Without knowing the full details of your configuration, I'll try my best to explain...</p>\n<p dir=\"auto\">For the <code class=\"notranslate\">ecs-deploy-runner</code> to be able to interact with the EKS cluster, the IAM Role the runner uses, must be mapped in the <code class=\"notranslate\">aws-auth</code> ConfigMap. Had the cluster been created with the IAM Role <code class=\"notranslate\">ecs-deploy-runner</code> is using, this would be unnecessary, as EKS implicitly grants admin RBAC for the IAM role that the cluster was created with. I'm assuming the cluster was created with a different role?</p>\n<p dir=\"auto\">To fix the issue, the ECS Deploy Runner IAM Role has to be added to <code class=\"notranslate\">aws-auth</code> ConfigMap. If you're using the  <a href=\"https://github.com/gruntwork-io/terraform-aws-eks/tree/master/modules/eks-aws-auth-merger\"><code class=\"notranslate\">eks-aws-auth-merger</code></a>, you can use the <a href=\"https://github.com/gruntwork-io/terraform-aws-eks/tree/master/modules/eks-k8s-role-mapping\"><code class=\"notranslate\">eks-k8s-role-mapping</code></a> to create an entry in the <code class=\"notranslate\">aws-auth</code> ConfigMap, e.g.</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"module &quot;ecs_deploy_runner_eks_k8s_role_mapping&quot; {\n  source = &quot;git::git@github.com:gruntwork-io/terraform-aws-eks.git//modules/eks-k8s-role-mapping?ref=v0.x.x&quot;\n\n  name      = &quot;ecs-deploy-runner&quot;\n  namespace = &quot;whatever-namespace-you-use-for-auth-merger&quot;\n\n  eks_worker_iam_role_arns                   = []\n  eks_fargate_profile_executor_iam_role_arns = []\n\n  iam_role_to_rbac_group_mappings = {\n    # I'm assuming you want admin level permissions in the cluster, because you'll be deploying\n    # RBAC resources, hence the system:masters\n    &quot;your-ecs-deploy-runner-iam-role&quot;    = [&quot;system:masters&quot;]\n  }\n\n  config_map_labels = {\n    eks-cluster = module.eks_cluster.eks_cluster_name\n  }\n}\"><pre class=\"notranslate\"><code class=\"notranslate\">module \"ecs_deploy_runner_eks_k8s_role_mapping\" {\n  source = \"git::git@github.com:gruntwork-io/terraform-aws-eks.git//modules/eks-k8s-role-mapping?ref=v0.x.x\"\n\n  name      = \"ecs-deploy-runner\"\n  namespace = \"whatever-namespace-you-use-for-auth-merger\"\n\n  eks_worker_iam_role_arns                   = []\n  eks_fargate_profile_executor_iam_role_arns = []\n\n  iam_role_to_rbac_group_mappings = {\n    # I'm assuming you want admin level permissions in the cluster, because you'll be deploying\n    # RBAC resources, hence the system:masters\n    \"your-ecs-deploy-runner-iam-role\"    = [\"system:masters\"]\n  }\n\n  config_map_labels = {\n    eks-cluster = module.eks_cluster.eks_cluster_name\n  }\n}\n</code></pre></div>\n<p dir=\"auto\">Make sure you're not overwriting the entire <code class=\"notranslate\">aws-auth</code> ConfigMap ðŸ˜… and check the plan results carefully before applying. Note that you'll have to deploy the module with an IAM Role that has sufficient permissions in the EKS cluster. After the <code class=\"notranslate\">aws-auth</code> ConfigMap has been updated, applying with the <code class=\"notranslate\">ecs-deploy-runner</code> should work.</p>\n<p dir=\"auto\">Hope this helps!</p>"}}} />

</CenterLayout>

<!-- ##DOCS-SOURCER-START
{
  "sourcePlugin": "github-discussions",
  "hash": "bb8a0c802bbfdb5c453dc83dc0fecb5e"
}
##DOCS-SOURCER-END -->
