---
hide_table_of_contents: true
hide_title: true
custom_edit_url: null
---

import CenterLayout from "/src/components/CenterLayout"
import GitHub from "/src/components/GitHub"

<head>
  <link rel="canonical" href="https://github.com/gruntwork-io/knowledge-base/discussions/418" />
</head>

<CenterLayout>
<span className="searchCategory">Knowledge Base</span>
<h1>How to rebuild a RefArch for a particular AWS account?</h1>
<GitHub discussion={{"id":"D_kwDOF8slf84APiXB","number":418,"author":{"login":"armartirosyan"},"title":"How to rebuild a RefArch for a particular AWS account?","body":"\nHello,\r\n\r\nI am trying to destroy the RefArc for the dev account and rebuild it.  The `terragrunt run-all destroy` command executed from the `infrastructure-live/dev` folder leads to the below error:\r\n\r\n```\r\n│ Error: local-exec provisioner error\r\n│\r\n│   with module.ecs_deploy_runner.module.ec2_ecs_cluster.aws_ecs_cluster.ecs[0],\r\n│   on .terraform/modules/ecs_deploy_runner.ec2_ecs_cluster/modules/ecs-cluster/main.tf line 64, in resource \"aws_ecs_cluster\" \"ecs\":\r\n│   64:   provisioner \"local-exec\" {\r\n│\r\n│ Error running command 'python\r\n│ .terraform/modules/ecs_deploy_runner.ec2_ecs_cluster/modules/ecs-cluster/shut-down-container-instances.py\r\n│ arn:aws:ecs:us-east-2:863730053613:cluster/ecs-deploy-runner': exit status\r\n│ 1. Output: [INFO] [shut-down-container-instances] 2022-05-11 17:21:43\r\n│ Starting shutdown process for container instances...\r\n│ [INFO] [shut-down-container-instances] 2022-05-11 17:21:43  Looking up\r\n│ container instances in ECS cluster\r\n│ arn:aws:ecs:us-east-2:863730053613:cluster/ecs-deploy-runner in us-east-2\r\n│ Traceback (most recent call last):\r\n│   File \"/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner/.terragrunt-cache/6UY0AdyeQXdycU0rUo2NG4PFWNM/fCw8UgbtyEKZwmAHcT_oAWkqDzs/modules/mgmt/ecs-deploy-runner/.terraform/modules/ecs_deploy_runner.ec2_ecs_cluster/modules/ecs-cluster/shut-down-container-instances.py\", line 322, in <module>\r\n│     run_shutdown_process(sys.argv)\r\n│   File \"/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner/.terragrunt-cache/6UY0AdyeQXdycU0rUo2NG4PFWNM/fCw8UgbtyEKZwmAHcT_oAWkqDzs/modules/mgmt/ecs-deploy-runner/.terraform/modules/ecs_deploy_runner.ec2_ecs_cluster/modules/ecs-cluster/shut-down-container-instances.py\", line 309, in run_shutdown_process\r\n│     container_instance_arns = get_container_instance_arns(ecs_cluster_arn, aws_region, logger)\r\n│   File \"/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner/.terragrunt-cache/6UY0AdyeQXdycU0rUo2NG4PFWNM/fCw8UgbtyEKZwmAHcT_oAWkqDzs/modules/mgmt/ecs-deploy-runner/.terraform/modules/ecs_deploy_runner.ec2_ecs_cluster/modules/ecs-cluster/shut-down-container-instances.py\", line 98, in get_container_instance_arns\r\n│     container_instances_output = run_aws_cli(list_args, aws_region)\r\n│   File \"/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner/.terragrunt-cache/6UY0AdyeQXdycU0rUo2NG4PFWNM/fCw8UgbtyEKZwmAHcT_oAWkqDzs/modules/mgmt/ecs-deploy-runner/.terraform/modules/ecs_deploy_runner.ec2_ecs_cluster/modules/ecs-cluster/shut-down-container-instances.py\", line 78, in run_aws_cli\r\n│     output = subprocess.check_output(['aws'] + args + common_args)\r\n│   File \"/home/user/.pyenv/versions/3.9.1/lib/python3.9/subprocess.py\", line 420, in check_output\r\n│     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\r\n│   File \"/home/user/.pyenv/versions/3.9.1/lib/python3.9/subprocess.py\", line 501, in run\r\n│     with Popen(*popenargs, **kwargs) as process:\r\n│   File \"/home/user/.pyenv/versions/3.9.1/lib/python3.9/subprocess.py\", line 947, in __init__\r\n│     self._execute_child(args, executable, preexec_fn, close_fds,\r\n│   File \"/home/user/.pyenv/versions/3.9.1/lib/python3.9/subprocess.py\", line 1819, in _execute_child\r\n│     raise child_exception_type(errno_num, err_msg, err_filename)\r\n│ FileNotFoundError: [Errno 2] No such file or directory: 'aws'\r\n│\r\n╵\r\nReleasing state lock. This may take a few moments...\r\nERRO[1766] Module /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner has finished with an error: 1 error occurred:\r\n        * exit status 1\r\n  prefix=[/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner]\r\nERRO[1766] Dependency /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner of module /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc just finished with an error. Module /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc will have to return an error too.  prefix=[/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc]\r\nERRO[1766] Module /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc has finished with an error: Cannot process module Module /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc (excluded: false, assume applied: false, dependencies: []) because one of its dependencies, Module /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner (excluded: false, assume applied: false, dependencies: [/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc]), finished with an error: 1 error occurred:\r\n        * exit status 1\r\n  prefix=[/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc]\r\nERRO[1766] 11 errors occurred:\r\n        * Cannot process module Module /home/user/Projects/infrastructure-live/dev/us-east-2/dev/networking/alb (excluded: false, assume applied: false, dependencies: [/home/user/Projects/infrastructure-live/dev/us-east-2/dev/networking/vpc, /home/user/Projects/infrastructure-live/dev/_global/route53-public]) because one of its dependencies, Module /home/user/Projects/infrastructure-live/dev/us-east-2/dev/services/ecs-cluster (excluded: false, assume applied: false, dependencies: [/home/user/Projects/infrastructure-live/dev/us-east-2/dev/networking/vpc, /home/user/Projects/infrastructure-live/dev/us-east-2/dev/networking/openvpn-server, /home/user/Projects/infrastructure-live/dev/us-east-2/_regional/sns-topic, /home/user/Projects/infrastructure-live/dev/us-east-2/dev/networking/alb, /home/user/Projects/infrastructure-live/dev/us-east-2/dev/networking/alb-internal]), finished with an error: 1 error occurred:\r\n        * exit status 1\r\n```\r\nWhat are the proper steps to destroy and then rebuild the RefArch in AWS? \r\nThanks!\n\n---\n\n<ins datetime=\"2022-05-13T20:10:20Z\">\n  <p><a href=\"https://support.gruntwork.io/hc/requests/108604\">Tracked in ticket #108604</a></p>\n</ins>\n","bodyHTML":"<p dir=\"auto\">Hello,</p>\n<p dir=\"auto\">I am trying to destroy the RefArc for the dev account and rebuild it.  The <code class=\"notranslate\">terragrunt run-all destroy</code> command executed from the <code class=\"notranslate\">infrastructure-live/dev</code> folder leads to the below error:</p>\n<div class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"│ Error: local-exec provisioner error\n│\n│   with module.ecs_deploy_runner.module.ec2_ecs_cluster.aws_ecs_cluster.ecs[0],\n│   on .terraform/modules/ecs_deploy_runner.ec2_ecs_cluster/modules/ecs-cluster/main.tf line 64, in resource &quot;aws_ecs_cluster&quot; &quot;ecs&quot;:\n│   64:   provisioner &quot;local-exec&quot; {\n│\n│ Error running command 'python\n│ .terraform/modules/ecs_deploy_runner.ec2_ecs_cluster/modules/ecs-cluster/shut-down-container-instances.py\n│ arn:aws:ecs:us-east-2:863730053613:cluster/ecs-deploy-runner': exit status\n│ 1. Output: [INFO] [shut-down-container-instances] 2022-05-11 17:21:43\n│ Starting shutdown process for container instances...\n│ [INFO] [shut-down-container-instances] 2022-05-11 17:21:43  Looking up\n│ container instances in ECS cluster\n│ arn:aws:ecs:us-east-2:863730053613:cluster/ecs-deploy-runner in us-east-2\n│ Traceback (most recent call last):\n│   File &quot;/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner/.terragrunt-cache/6UY0AdyeQXdycU0rUo2NG4PFWNM/fCw8UgbtyEKZwmAHcT_oAWkqDzs/modules/mgmt/ecs-deploy-runner/.terraform/modules/ecs_deploy_runner.ec2_ecs_cluster/modules/ecs-cluster/shut-down-container-instances.py&quot;, line 322, in &lt;module&gt;\n│     run_shutdown_process(sys.argv)\n│   File &quot;/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner/.terragrunt-cache/6UY0AdyeQXdycU0rUo2NG4PFWNM/fCw8UgbtyEKZwmAHcT_oAWkqDzs/modules/mgmt/ecs-deploy-runner/.terraform/modules/ecs_deploy_runner.ec2_ecs_cluster/modules/ecs-cluster/shut-down-container-instances.py&quot;, line 309, in run_shutdown_process\n│     container_instance_arns = get_container_instance_arns(ecs_cluster_arn, aws_region, logger)\n│   File &quot;/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner/.terragrunt-cache/6UY0AdyeQXdycU0rUo2NG4PFWNM/fCw8UgbtyEKZwmAHcT_oAWkqDzs/modules/mgmt/ecs-deploy-runner/.terraform/modules/ecs_deploy_runner.ec2_ecs_cluster/modules/ecs-cluster/shut-down-container-instances.py&quot;, line 98, in get_container_instance_arns\n│     container_instances_output = run_aws_cli(list_args, aws_region)\n│   File &quot;/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner/.terragrunt-cache/6UY0AdyeQXdycU0rUo2NG4PFWNM/fCw8UgbtyEKZwmAHcT_oAWkqDzs/modules/mgmt/ecs-deploy-runner/.terraform/modules/ecs_deploy_runner.ec2_ecs_cluster/modules/ecs-cluster/shut-down-container-instances.py&quot;, line 78, in run_aws_cli\n│     output = subprocess.check_output(['aws'] + args + common_args)\n│   File &quot;/home/user/.pyenv/versions/3.9.1/lib/python3.9/subprocess.py&quot;, line 420, in check_output\n│     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n│   File &quot;/home/user/.pyenv/versions/3.9.1/lib/python3.9/subprocess.py&quot;, line 501, in run\n│     with Popen(*popenargs, **kwargs) as process:\n│   File &quot;/home/user/.pyenv/versions/3.9.1/lib/python3.9/subprocess.py&quot;, line 947, in __init__\n│     self._execute_child(args, executable, preexec_fn, close_fds,\n│   File &quot;/home/user/.pyenv/versions/3.9.1/lib/python3.9/subprocess.py&quot;, line 1819, in _execute_child\n│     raise child_exception_type(errno_num, err_msg, err_filename)\n│ FileNotFoundError: [Errno 2] No such file or directory: 'aws'\n│\n╵\nReleasing state lock. This may take a few moments...\nERRO[1766] Module /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner has finished with an error: 1 error occurred:\n        * exit status 1\n  prefix=[/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner]\nERRO[1766] Dependency /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner of module /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc just finished with an error. Module /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc will have to return an error too.  prefix=[/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc]\nERRO[1766] Module /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc has finished with an error: Cannot process module Module /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc (excluded: false, assume applied: false, dependencies: []) because one of its dependencies, Module /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner (excluded: false, assume applied: false, dependencies: [/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc]), finished with an error: 1 error occurred:\n        * exit status 1\n  prefix=[/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc]\nERRO[1766] 11 errors occurred:\n        * Cannot process module Module /home/user/Projects/infrastructure-live/dev/us-east-2/dev/networking/alb (excluded: false, assume applied: false, dependencies: [/home/user/Projects/infrastructure-live/dev/us-east-2/dev/networking/vpc, /home/user/Projects/infrastructure-live/dev/_global/route53-public]) because one of its dependencies, Module /home/user/Projects/infrastructure-live/dev/us-east-2/dev/services/ecs-cluster (excluded: false, assume applied: false, dependencies: [/home/user/Projects/infrastructure-live/dev/us-east-2/dev/networking/vpc, /home/user/Projects/infrastructure-live/dev/us-east-2/dev/networking/openvpn-server, /home/user/Projects/infrastructure-live/dev/us-east-2/_regional/sns-topic, /home/user/Projects/infrastructure-live/dev/us-east-2/dev/networking/alb, /home/user/Projects/infrastructure-live/dev/us-east-2/dev/networking/alb-internal]), finished with an error: 1 error occurred:\n        * exit status 1\"><pre class=\"notranslate\"><code class=\"notranslate\">│ Error: local-exec provisioner error\n│\n│   with module.ecs_deploy_runner.module.ec2_ecs_cluster.aws_ecs_cluster.ecs[0],\n│   on .terraform/modules/ecs_deploy_runner.ec2_ecs_cluster/modules/ecs-cluster/main.tf line 64, in resource \"aws_ecs_cluster\" \"ecs\":\n│   64:   provisioner \"local-exec\" {\n│\n│ Error running command 'python\n│ .terraform/modules/ecs_deploy_runner.ec2_ecs_cluster/modules/ecs-cluster/shut-down-container-instances.py\n│ arn:aws:ecs:us-east-2:863730053613:cluster/ecs-deploy-runner': exit status\n│ 1. Output: [INFO] [shut-down-container-instances] 2022-05-11 17:21:43\n│ Starting shutdown process for container instances...\n│ [INFO] [shut-down-container-instances] 2022-05-11 17:21:43  Looking up\n│ container instances in ECS cluster\n│ arn:aws:ecs:us-east-2:863730053613:cluster/ecs-deploy-runner in us-east-2\n│ Traceback (most recent call last):\n│   File \"/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner/.terragrunt-cache/6UY0AdyeQXdycU0rUo2NG4PFWNM/fCw8UgbtyEKZwmAHcT_oAWkqDzs/modules/mgmt/ecs-deploy-runner/.terraform/modules/ecs_deploy_runner.ec2_ecs_cluster/modules/ecs-cluster/shut-down-container-instances.py\", line 322, in &lt;module&gt;\n│     run_shutdown_process(sys.argv)\n│   File \"/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner/.terragrunt-cache/6UY0AdyeQXdycU0rUo2NG4PFWNM/fCw8UgbtyEKZwmAHcT_oAWkqDzs/modules/mgmt/ecs-deploy-runner/.terraform/modules/ecs_deploy_runner.ec2_ecs_cluster/modules/ecs-cluster/shut-down-container-instances.py\", line 309, in run_shutdown_process\n│     container_instance_arns = get_container_instance_arns(ecs_cluster_arn, aws_region, logger)\n│   File \"/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner/.terragrunt-cache/6UY0AdyeQXdycU0rUo2NG4PFWNM/fCw8UgbtyEKZwmAHcT_oAWkqDzs/modules/mgmt/ecs-deploy-runner/.terraform/modules/ecs_deploy_runner.ec2_ecs_cluster/modules/ecs-cluster/shut-down-container-instances.py\", line 98, in get_container_instance_arns\n│     container_instances_output = run_aws_cli(list_args, aws_region)\n│   File \"/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner/.terragrunt-cache/6UY0AdyeQXdycU0rUo2NG4PFWNM/fCw8UgbtyEKZwmAHcT_oAWkqDzs/modules/mgmt/ecs-deploy-runner/.terraform/modules/ecs_deploy_runner.ec2_ecs_cluster/modules/ecs-cluster/shut-down-container-instances.py\", line 78, in run_aws_cli\n│     output = subprocess.check_output(['aws'] + args + common_args)\n│   File \"/home/user/.pyenv/versions/3.9.1/lib/python3.9/subprocess.py\", line 420, in check_output\n│     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n│   File \"/home/user/.pyenv/versions/3.9.1/lib/python3.9/subprocess.py\", line 501, in run\n│     with Popen(*popenargs, **kwargs) as process:\n│   File \"/home/user/.pyenv/versions/3.9.1/lib/python3.9/subprocess.py\", line 947, in __init__\n│     self._execute_child(args, executable, preexec_fn, close_fds,\n│   File \"/home/user/.pyenv/versions/3.9.1/lib/python3.9/subprocess.py\", line 1819, in _execute_child\n│     raise child_exception_type(errno_num, err_msg, err_filename)\n│ FileNotFoundError: [Errno 2] No such file or directory: 'aws'\n│\n╵\nReleasing state lock. This may take a few moments...\nERRO[1766] Module /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner has finished with an error: 1 error occurred:\n        * exit status 1\n  prefix=[/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner]\nERRO[1766] Dependency /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner of module /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc just finished with an error. Module /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc will have to return an error too.  prefix=[/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc]\nERRO[1766] Module /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc has finished with an error: Cannot process module Module /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc (excluded: false, assume applied: false, dependencies: []) because one of its dependencies, Module /home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/ecs-deploy-runner (excluded: false, assume applied: false, dependencies: [/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc]), finished with an error: 1 error occurred:\n        * exit status 1\n  prefix=[/home/user/Projects/infrastructure-live/dev/us-east-2/mgmt/networking/vpc]\nERRO[1766] 11 errors occurred:\n        * Cannot process module Module /home/user/Projects/infrastructure-live/dev/us-east-2/dev/networking/alb (excluded: false, assume applied: false, dependencies: [/home/user/Projects/infrastructure-live/dev/us-east-2/dev/networking/vpc, /home/user/Projects/infrastructure-live/dev/_global/route53-public]) because one of its dependencies, Module /home/user/Projects/infrastructure-live/dev/us-east-2/dev/services/ecs-cluster (excluded: false, assume applied: false, dependencies: [/home/user/Projects/infrastructure-live/dev/us-east-2/dev/networking/vpc, /home/user/Projects/infrastructure-live/dev/us-east-2/dev/networking/openvpn-server, /home/user/Projects/infrastructure-live/dev/us-east-2/_regional/sns-topic, /home/user/Projects/infrastructure-live/dev/us-east-2/dev/networking/alb, /home/user/Projects/infrastructure-live/dev/us-east-2/dev/networking/alb-internal]), finished with an error: 1 error occurred:\n        * exit status 1\n</code></pre></div>\n<p dir=\"auto\">What are the proper steps to destroy and then rebuild the RefArch in AWS?<br>\nThanks!</p>\n<hr>\n<ins datetime=\"2022-05-13T20:10:20Z\">\n  <p dir=\"auto\"><a href=\"https://support.gruntwork.io/hc/requests/108604\" rel=\"nofollow\">Tracked in ticket #108604</a></p>\n</ins>","answer":{"body":"Hi @armartirosyan, \r\n\r\nIn this particular case, based on the stack trace you've shared, it looks like you do not have the latest AWS Python SDK (boto3) installed on your system. Since the python scripts in our ecs-module require the AWS Python SDK to be installed locally, you're getting this error because our scripts are trying to invoke a binary you don't have installed. \r\n\r\nPlease review [these instructions in the ecs-module README](https://github.com/gruntwork-io/terraform-aws-ecs/tree/master/modules/ecs-cluster#how-to-use-the-roll-out-ecs-cluster-updatepy-script) to install AWS's Python SDK (the instructions are to run `pip install boto3`). \r\n\r\nHope this helps!\r\n","bodyHTML":"<p dir=\"auto\">Hi <a class=\"user-mention notranslate\" data-hovercard-type=\"user\" data-hovercard-url=\"/users/armartirosyan/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/armartirosyan\">@armartirosyan</a>,</p>\n<p dir=\"auto\">In this particular case, based on the stack trace you've shared, it looks like you do not have the latest AWS Python SDK (boto3) installed on your system. Since the python scripts in our ecs-module require the AWS Python SDK to be installed locally, you're getting this error because our scripts are trying to invoke a binary you don't have installed.</p>\n<p dir=\"auto\">Please review <a href=\"https://github.com/gruntwork-io/terraform-aws-ecs/tree/master/modules/ecs-cluster#how-to-use-the-roll-out-ecs-cluster-updatepy-script\">these instructions in the ecs-module README</a> to install AWS's Python SDK (the instructions are to run <code class=\"notranslate\">pip install boto3</code>).</p>\n<p dir=\"auto\">Hope this helps!</p>"}}} />

</CenterLayout>
  

<!-- ##DOCS-SOURCER-START
{
  "sourcePlugin": "github-discussions",
  "hash": "9e91ff90ed42331ea1dffa52ccde1db2"
}
##DOCS-SOURCER-END -->
